{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301eefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "from google import genai\n",
    "\n",
    "# PubMedQA 평가를 위한 라이브러리 추가\n",
    "from datasets import load_dataset\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "client = genai.Client(api_key='AIzaSyDNXwI-Zc3vyyPbQFKaJvJxtIXxW5r9Ltc')\n",
    "\n",
    "\n",
    "for m in client.models.list():\n",
    "  if 'embedContent' in m.supported_actions:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9f7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "  def __call__(self, input: Documents) -> Embeddings:\n",
    "    EMBEDDING_MODEL_ID = \"models/text-embedding-004\"\n",
    "    title = \"Custom query\"\n",
    "    response = client.models.embed_content(\n",
    "        model=EMBEDDING_MODEL_ID,\n",
    "        contents=input,\n",
    "        config=types.EmbedContentConfig(\n",
    "          task_type=\"retrieval_document\",\n",
    "          title=title\n",
    "        )\n",
    "    )\n",
    "    # 모든 문서의 임베딩 벡터를 리스트로 반환\n",
    "    return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322eb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dopar\\AppData\\Local\\Temp\\ipykernel_8956\\1664504859.py:27: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function=GeminiEmbeddingFunction()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m db_long_answers\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# PubMedQA 데이터셋 로드\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m pubmedqa_dataset = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpubmed_qa\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpqa_labeled\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# long_answer 임베딩 및 Chroma DB 생성\u001b[39;00m\n\u001b[32m     88\u001b[39m db_pubmedqa_long_answers = create_pubmedqa_long_answer_embeddings(pubmedqa_dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\load.py:2062\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2057\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   2058\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   2059\u001b[39m )\n\u001b[32m   2061\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2062\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2075\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2076\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   2080\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\load.py:1819\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[39m\n\u001b[32m   1817\u001b[39m builder_cls = get_dataset_builder_class(dataset_module, dataset_name=dataset_name)\n\u001b[32m   1818\u001b[39m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1819\u001b[39m builder_instance: DatasetBuilder = \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1825\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mdataset_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1826\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1830\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1833\u001b[39m builder_instance._use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[32m   1835\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\builder.py:343\u001b[39m, in \u001b[36mDatasetBuilder.__init__\u001b[39m\u001b[34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, repo_id, data_files, data_dir, storage_options, writer_batch_size, **config_kwargs)\u001b[39m\n\u001b[32m    341\u001b[39m     config_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata_dir\u001b[39m\u001b[33m\"\u001b[39m] = data_dir\n\u001b[32m    342\u001b[39m \u001b[38;5;28mself\u001b[39m.config_kwargs = config_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28mself\u001b[39m.config, \u001b[38;5;28mself\u001b[39m.config_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    352\u001b[39m     \u001b[38;5;66;03m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\builder.py:598\u001b[39m, in \u001b[36mDatasetBuilder._create_builder_config\u001b[39m\u001b[34m(self, config_name, custom_features, **config_kwargs)\u001b[39m\n\u001b[32m    595\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBuilderConfig must have a name, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuilder_config.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# resolve data files if needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[43mbuilder_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_resolve_data_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDownloadConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# compute the config id that is going to be used for caching\u001b[39;00m\n\u001b[32m    604\u001b[39m config_id = builder_config.create_config_id(\n\u001b[32m    605\u001b[39m     config_kwargs,\n\u001b[32m    606\u001b[39m     custom_features=custom_features,\n\u001b[32m    607\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\builder.py:207\u001b[39m, in \u001b[36mBuilderConfig._resolve_data_files\u001b[39m\u001b[34m(self, base_path, download_config)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.data_files, DataFilesPatternsDict):\n\u001b[32m    206\u001b[39m     base_path = xjoin(base_path, \u001b[38;5;28mself\u001b[39m.data_dir) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data_dir \u001b[38;5;28;01melse\u001b[39;00m base_path\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28mself\u001b[39m.data_files = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\data_files.py:788\u001b[39m, in \u001b[36mDataFilesPatternsDict.resolve\u001b[39m\u001b[34m(self, base_path, download_config)\u001b[39m\n\u001b[32m    786\u001b[39m out = DataFilesDict()\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, data_files_patterns_list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items():\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     out[key] = \u001b[43mdata_files_patterns_list\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\data_files.py:741\u001b[39m, in \u001b[36mDataFilesPatternsList.resolve\u001b[39m\u001b[34m(self, base_path, download_config)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pattern, allowed_extensions \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.allowed_extensions):\n\u001b[32m    739\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    740\u001b[39m         data_files.extend(\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m         )\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m    749\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\datasets\\data_files.py:360\u001b[39m, in \u001b[36mresolve_pattern\u001b[39m\u001b[34m(pattern, base_path, allowed_extensions, download_config)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m protocol == \u001b[33m\"\u001b[39m\u001b[33mhf\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m config.HF_HUB_VERSION >= version.parse(\u001b[33m\"\u001b[39m\u001b[33m0.20.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    356\u001b[39m     \u001b[38;5;66;03m# 10 times faster glob with detail=True (ignores costly info like lastCommit)\u001b[39;00m\n\u001b[32m    357\u001b[39m     glob_kwargs[\u001b[33m\"\u001b[39m\u001b[33mexpand_info\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    358\u001b[39m matched_paths = [\n\u001b[32m    359\u001b[39m     filepath \u001b[38;5;28;01mif\u001b[39;00m filepath.startswith(protocol_prefix) \u001b[38;5;28;01melse\u001b[39;00m protocol_prefix + filepath\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m filepath, info \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mglob_kwargs\u001b[49m\u001b[43m)\u001b[49m.items()\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (info[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (info.get(\u001b[33m\"\u001b[39m\u001b[33mislink\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os.path.isfile(os.path.realpath(filepath))))\n\u001b[32m    362\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (xbasename(filepath) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m files_to_ignore)\n\u001b[32m    363\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_inside_unrequested_special_dir(filepath, fs_pattern)\n\u001b[32m    364\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir(filepath, fs_pattern)\n\u001b[32m    365\u001b[39m ]  \u001b[38;5;66;03m# ignore .ipynb and __pycache__, but keep /../\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    367\u001b[39m     out = [\n\u001b[32m    368\u001b[39m         filepath\n\u001b[32m    369\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m matched_paths\n\u001b[32m    370\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + suffix \u001b[38;5;129;01min\u001b[39;00m allowed_extensions \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m xbasename(filepath).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m1\u001b[39m:])\n\u001b[32m    371\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:521\u001b[39m, in \u001b[36mHfFileSystem.glob\u001b[39m\u001b[34m(self, path, **kwargs)\u001b[39m\n\u001b[32m    519\u001b[39m kwargs = {\u001b[33m\"\u001b[39m\u001b[33mexpand_info\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mdetail\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), **kwargs}\n\u001b[32m    520\u001b[39m path = \u001b[38;5;28mself\u001b[39m.resolve_path(path, revision=kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrevision\u001b[39m\u001b[33m\"\u001b[39m)).unresolve()\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\fsspec\\spec.py:609\u001b[39m, in \u001b[36mAbstractFileSystem.glob\u001b[39m\u001b[34m(self, path, maxdepth, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    607\u001b[39m         depth = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m allpaths = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    611\u001b[39m pattern = glob_translate(path + (\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ends_with_sep \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    612\u001b[39m pattern = re.compile(pattern)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:556\u001b[39m, in \u001b[36mHfFileSystem.find\u001b[39m\u001b[34m(self, path, maxdepth, withdirs, detail, refresh, revision, **kwargs)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[33;03mList all files below path.\u001b[39;00m\n\u001b[32m    535\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    553\u001b[39m \u001b[33;03m    `Union[List[str], Dict[str, Dict[str, Any]]]`: List of paths or dict of file information.\u001b[39;00m\n\u001b[32m    554\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxdepth:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m resolved_path = \u001b[38;5;28mself\u001b[39m.resolve_path(path, revision=revision)\n\u001b[32m    560\u001b[39m path = resolved_path.unresolve()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\fsspec\\spec.py:502\u001b[39m, in \u001b[36mAbstractFileSystem.find\u001b[39m\u001b[34m(self, path, maxdepth, withdirs, detail, **kwargs)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m withdirs \u001b[38;5;129;01mand\u001b[39;00m path != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isdir(path):\n\u001b[32m    500\u001b[39m     out[path] = \u001b[38;5;28mself\u001b[39m.info(path)\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:503\u001b[39m, in \u001b[36mHfFileSystem.walk\u001b[39m\u001b[34m(self, path, *args, **kwargs)\u001b[39m\n\u001b[32m    501\u001b[39m kwargs = {\u001b[33m\"\u001b[39m\u001b[33mexpand_info\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mdetail\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), **kwargs}\n\u001b[32m    502\u001b[39m path = \u001b[38;5;28mself\u001b[39m.resolve_path(path, revision=kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrevision\u001b[39m\u001b[33m\"\u001b[39m)).unresolve()\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().walk(path, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\fsspec\\spec.py:427\u001b[39m, in \u001b[36mAbstractFileSystem.walk\u001b[39m\u001b[34m(self, path, maxdepth, topdown, on_error, **kwargs)\u001b[39m\n\u001b[32m    425\u001b[39m detail = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdetail\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     listing = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m on_error == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:372\u001b[39m, in \u001b[36mHfFileSystem.ls\u001b[39m\u001b[34m(self, path, detail, refresh, revision, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m kwargs = {\u001b[33m\"\u001b[39m\u001b[33mexpand_info\u001b[39m\u001b[33m\"\u001b[39m: detail, **kwargs}\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ls_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n\u001b[32m    374\u001b[39m     \u001b[38;5;66;03m# Path could be a file\u001b[39;00m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resolved_path.path_in_repo:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:463\u001b[39m, in \u001b[36mHfFileSystem._ls_tree\u001b[39m\u001b[34m(self, path, recursive, refresh, revision, expand_info)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    455\u001b[39m     tree = \u001b[38;5;28mself\u001b[39m._api.list_repo_tree(\n\u001b[32m    456\u001b[39m         resolved_path.repo_id,\n\u001b[32m    457\u001b[39m         resolved_path.path_in_repo,\n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m         repo_type=resolved_path.repo_type,\n\u001b[32m    462\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRepoFile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_path_info\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msecurity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43msecurity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\hf_api.py:3168\u001b[39m, in \u001b[36mHfApi.list_repo_tree\u001b[39m\u001b[34m(self, repo_id, path_in_repo, recursive, expand, revision, repo_type, token)\u001b[39m\n\u001b[32m   3166\u001b[39m encoded_path_in_repo = \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + quote(path_in_repo, safe=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m path_in_repo \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3167\u001b[39m tree_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.endpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mencoded_path_in_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m3168\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpaginate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtree_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursive\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpand\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mRepoFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mRepoFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\utils\\_pagination.py:36\u001b[39m, in \u001b[36mpaginate\u001b[39m\u001b[34m(path, params, headers)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fetch a list of models/datasets/spaces and paginate through results.\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[33;03mThis is using the same \"Link\" header format as GitHub.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[33;03m- https://docs.github.com/en/rest/guides/traversing-with-pagination#link-header\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m session = get_session()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m r = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m hf_raise_for_status(r)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\requests\\sessions.py:724\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[32m    722\u001b[39m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[32m    723\u001b[39m     gen = \u001b[38;5;28mself\u001b[39m.resolve_redirects(r, request, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     history = \u001b[43m[\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    726\u001b[39m     history = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\requests\\sessions.py:265\u001b[39m, in \u001b[36mSessionRedirectMixin.resolve_redirects\u001b[39m\u001b[34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m.cookies, prepared_request, resp.raw)\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:96\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dopar\\anaconda3\\envs\\pyhome\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "#chroma_client.delete_collection(\"my_collection\")\n",
    "def preprocess_metadata(metadata):\n",
    "    new_metadata = {}\n",
    "    for k, v in metadata.items():\n",
    "        if isinstance(v, list):\n",
    "            new_metadata[k] = \", \".join(map(str, v))  # 리스트를 문자열로 변환\n",
    "        else:\n",
    "            new_metadata[k] = v\n",
    "    return new_metadata\n",
    "def batch_add(collection, documents, metadatas, ids, batch_size=100):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch_docs = documents[i:i+batch_size]\n",
    "        batch_metas = metadatas[i:i+batch_size]\n",
    "        batch_ids = ids[i:i+batch_size]\n",
    "        collection.add(\n",
    "            documents=batch_docs,\n",
    "            metadatas=batch_metas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "def create_chroma_db(json_data, name):\n",
    "    import chromadb\n",
    "\n",
    "    chroma_client = chromadb.Client()\n",
    "    db = chroma_client.create_collection(\n",
    "        name=name,\n",
    "        embedding_function=GeminiEmbeddingFunction()\n",
    "    )\n",
    "\n",
    "    # JSON 데이터에서 텍스트, 메타데이터, id 추출\n",
    "    documents = [item[\"text\"] for item in json_data]\n",
    "    metadatas = [preprocess_metadata(item[\"metadata\"]) for item in json_data]\n",
    "    ids = [str(i) for i in range(len(json_data))]\n",
    "    \n",
    "    batch_add(db, documents, metadatas, ids, batch_size=100)\n",
    "   \n",
    "    return db\n",
    "with open('disease_rag_with_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "db = create_chroma_db(data, \"my_collection\")\n",
    "\n",
    "# PubMedQA long_answer 임베딩을 위한 코드 추가\n",
    "def create_pubmedqa_long_answer_embeddings(pubmedqa_dataset, collection_name=\"pubmedqa_long_answers\"):\n",
    "    chroma_client = chromadb.Client()\n",
    "    \n",
    "    # Check if collection already exists and delete it to start fresh\n",
    "    try:\n",
    "        chroma_client.delete_collection(collection_name)\n",
    "        print(f\"Existing collection '{collection_name}' deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"No existing collection '{collection_name}' to delete or error during deletion: {e}\")\n",
    "\n",
    "    db_long_answers = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=GeminiEmbeddingFunction()\n",
    "    )\n",
    "\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    for i, entry in enumerate(pubmedqa_dataset['train']):\n",
    "        question = entry['question']\n",
    "        context = \" \".join(entry['context']['contexts'])\n",
    "        long_answer = entry['long_answer']\n",
    "        final_decision = entry['final_decision']\n",
    "\n",
    "        # Combine relevant information into a single document string for embedding\n",
    "        document_text = f\"Question: {question} Context: {context} Answer: {final_decision}\"\n",
    "        \n",
    "        documents.append(document_text)\n",
    "        metadatas.append({\n",
    "            \"question\": question,\n",
    "            \"final_decision\": final_decision,\n",
    "            \"context\": context\n",
    "        })\n",
    "        ids.append(str(i))\n",
    "    \n",
    "    batch_add(db_long_answers, documents, metadatas, ids, batch_size=100)\n",
    "    print(f\"Successfully created and populated '{collection_name}' with {len(documents)} documents.\")\n",
    "    return db_long_answers\n",
    "\n",
    "# PubMedQA 데이터셋 로드\n",
    "pubmedqa_dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\")\n",
    "\n",
    "# long_answer 임베딩 및 Chroma DB 생성\n",
    "db_pubmedqa_long_answers = create_pubmedqa_long_answer_embeddings(pubmedqa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  IDs                                          Documents  \\\n",
      "0   0  증상: Fever, Fatigue, Difficulty Breathing이(가) 있...   \n",
      "1   1  증상: Cough, Fatigue이(가) 있고, 나이: 25세, 성별: Female...   \n",
      "2   2  증상: Cough, Fatigue이(가) 있고, 나이: 25세, 성별: Female...   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [ 0.00477051  0.04616465 -0.06666899 -0.040444...  \n",
      "1  [-3.57129462e-02  7.49278739e-02 -6.56882823e-...  \n",
      "2  [-3.55055146e-02  4.89426367e-02 -6.10607862e-...  \n",
      "\n",
      "--- Sample PubMedQA Long Answer Embeddings ---\n",
      "  IDs                                          Documents  \\\n",
      "0   0  Question: Do mitochondria play a role in remod...   \n",
      "1   1  Question: Landolt C and snellen e acuity: diff...   \n",
      "2   2  Question: Syncope during bathing in infants, a...   \n",
      "\n",
      "                                           Metadatas  \\\n",
      "0  {'context': 'Programmed cell death (PCD) is th...   \n",
      "1  {'final_decision': 'no', 'context': 'Assessmen...   \n",
      "2  {'question': 'Syncope during bathing in infant...   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [-4.83142845e-02  3.91270705e-02 -6.88774511e-...  \n",
      "1  [ 4.58505452e-02  4.41183709e-03 -1.36079304e-...  \n",
      "2  [ 3.41068069e-03 -1.07322438e-02 -6.37394786e-...  \n"
     ]
    }
   ],
   "source": [
    "sample_data = db.get(include=['documents', 'embeddings'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"IDs\": sample_data['ids'][:3],\n",
    "    \"Documents\": sample_data['documents'][:3],\n",
    "    \"Embeddings\": [str(emb)[:50] + \"...\" for emb in sample_data['embeddings'][:3]]  # Truncate embeddings\n",
    "})\n",
    "print(df)\n",
    "\n",
    "sample_long_answer_data = db_pubmedqa_long_answers.get(include=['documents', 'embeddings', 'metadatas'], limit=3)\n",
    "df_long_answers = pd.DataFrame({\n",
    "    \"IDs\": sample_long_answer_data['ids'],\n",
    "    \"Documents\": sample_long_answer_data['documents'],\n",
    "    \"Metadatas\": sample_long_answer_data['metadatas'],\n",
    "    \"Embeddings\": [str(emb)[:50] + \"...\" for emb in sample_long_answer_data['embeddings']]\n",
    "})\n",
    "print(\"\\n--- Sample PubMedQA Long Answer Embeddings ---\")\n",
    "print(df_long_answers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4861eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using general disease database (profile-specific query detected).\n",
      "\n",
      "--- Passages for General Query ---\n",
      "증상: Fever이(가) 있고, 나이: 31세, 성별: Female, 혈압: Normal, 콜레스테롤: Normal인 환자의 경우 Migraine일 수 있습니다. (나이: 31, 성별: Female, 혈압: Normal, 콜레스테롤: Normal)\n",
      "증상: Fever이(가) 있고, 나이: 25세, 성별: Female, 혈압: Normal, 콜레스테롤: Normal인 환자의 경우 Eczema일 수 있습니다. (나이: 25, 성별: Female, 혈압: Normal, 콜레스테롤: Normal)\n",
      "증상: Fever, Cough, Difficulty Breathing이(가) 있고, 나이: 30세, 성별: Female, 혈압: Normal, 콜레스테롤: Normal인 환자의 경우 Asthma일 수 있습니다. (나이: 30, 성별: Female, 혈압: Normal, 콜레스테롤: Normal)\n",
      "증상: Fever, Cough, Difficulty Breathing이(가) 있고, 나이: 30세, 성별: Female, 혈압: Normal, 콜레스테롤: Normal인 환자의 경우 Asthma일 수 있습니다. (나이: 30, 성별: Female, 혈압: Normal, 콜레스테롤: Normal)\n",
      "증상: Fever, Difficulty Breathing이(가) 있고, 나이: 42세, 성별: Female, 혈압: Normal, 콜레스테롤: Normal인 환자의 경우 Liver Disease일 수 있습니다. (나이: 42, 성별: Female, 혈압: Normal, 콜레스테롤: Normal)\n",
      "--------------------------------------------------\n",
      "Using PubMedQA medical QA database (medical keywords detected).\n",
      "\n",
      "--- Passages for Medical QA Query ---\n",
      "Question: Can tailored interventions increase mammography use among HMO women? Context: Telephone counseling and tailored print communications have emerged as promising methods for promoting mammography screening. However, there has been little research testing, within the same randomized field trial, of the efficacy of these two methods compared to a high-quality usual care system for enhancing screening. This study addressed the question: Compared to usual care, is tailored telephone counseling more effective than tailored print materials for promoting mammography screening? Three-year randomized field trial. One thousand ninety-nine women aged 50 and older recruited from a health maintenance organization in North Carolina. Women were randomized to 1 of 3 groups: (1) usual care, (2) tailored print communications, and (3) tailored telephone counseling. Adherence to mammography screening based on self-reports obtained during 1995, 1996, and 1997. Compared to usual care alone, telephone counseling promoted a significantly higher proportion of women having mammograms on schedule (71% vs 61%) than did tailored print (67% vs 61%) but only after the first year of intervention (during 1996). Furthermore, compared to usual care, telephone counseling was more effective than tailored print materials at promoting being on schedule with screening during 1996 and 1997 among women who were off-schedule during the previous year. Answer: Question: Can tailored interventions increase mammography use among HMO women? Context: Telephone counseling and tailored print communications have emerged as promising methods for promoting mammography screening. However, there has been little research testing, within the same randomized field trial, of the efficacy of these two methods compared to a high-quality usual care system for enhancing screening. This study addressed the question: Compared to usual care, is tailored telephone counseling more effective than tailored print materials for promoting mammography screening? Three-year randomized field trial. One thousand ninety-nine women aged 50 and older recruited from a health maintenance organization in North Carolina. Women were randomized to 1 of 3 groups: (1) usual care, (2) tailored print communications, and (3) tailored telephone counseling. Adherence to mammography screening based on self-reports obtained during 1995, 1996, and 1997. Compared to usual care alone, telephone counseling promoted a significantly higher proportion of women having mammograms on schedule (71% vs 61%) than did tailored print (67% vs 61%) but only after the first year of intervention (during 1996). Furthermore, compared to usual care, telephone counseling was more effective than tailored print materials at promoting being on schedule with screening during 1996 and 1997 among women who were off-schedule during the previous year. Answer: The effects of the intervention were most pronounced after the first intervention. Compared to usual care, telephone counseling seemed particularly effective at promoting change among nonadherent women, the group for whom the intervention was developed. These results suggest that telephone counseling, rather than tailored print, might be the preferred first-line intervention for getting nonadherent women on schedule for mammography screening. Many questions would have to be answered about why the tailored print intervention was not more powerful. Nevertheless, it is clear that additional interventions will be needed to maintain women's adherence to mammography. Medical Subject Headings (MeSH): mammography screening, telephone counseling, tailored print communications, barriers.\n",
      "Question: Prompting Primary Care Providers about Increased Patient Risk As a Result of Family History: Does It Work? Context: Electronic health records have the potential to facilitate family history use by primary care physicians (PCPs) to provide personalized care. The objective of this study was to determine whether automated, at-the-visit tailored prompts about family history risk change PCP behavior. Automated, tailored prompts highlighting familial risk for heart disease, stroke, diabetes, and breast, colorectal, or ovarian cancer were implemented during 2011 to 2012. Medical records of a cohort of community-based primary care patients, aged 35 to 65 years, who previously participated in our Family Healthware study and had a moderate or strong familial risk for any of the 6 diseases were subsequently reviewed. The main outcome measures were PCP response to the prompts, adding family history risk to problem summary lists, and patient screening status for each disease. The 492 eligible patients had 847 visits during the study period; 152 visits had no documentation of response to a family history prompt. Of the remaining 695 visits, physician responses were reviewed family history (n = 372, 53.5%), discussed family history (n = 159, 22.9%), not addressed (n = 155, 22.3%), and reviewed family history and ordered tests/referrals (n = 5, 0.7%). There was no significant change in problem summary list documentation of risk status or screening interventions for any of the 6 diseases. Answer: Question: Prompting Primary Care Providers about Increased Patient Risk As a Result of Family History: Does It Work? Context: Electronic health records have the potential to facilitate family history use by primary care physicians (PCPs) to provide personalized care. The objective of this study was to determine whether automated, at-the-visit tailored prompts about family history risk change PCP behavior. Automated, tailored prompts highlighting familial risk for heart disease, stroke, diabetes, and breast, colorectal, or ovarian cancer were implemented during 2011 to 2012. Medical records of a cohort of community-based primary care patients, aged 35 to 65 years, who previously participated in our Family Healthware study and had a moderate or strong familial risk for any of the 6 diseases were subsequently reviewed. The main outcome measures were PCP response to the prompts, adding family history risk to problem summary lists, and patient screening status for each disease. The 492 eligible patients had 847 visits during the study period; 152 visits had no documentation of response to a family history prompt. Of the remaining 695 visits, physician responses were reviewed family history (n = 372, 53.5%), discussed family history (n = 159, 22.9%), not addressed (n = 155, 22.3%), and reviewed family history and ordered tests/referrals (n = 5, 0.7%). There was no significant change in problem summary list documentation of risk status or screening interventions for any of the 6 diseases. Answer: No change occurred upon instituting simple, at-the-visit family history prompts geared to improve PCPs' ability to identify patients at high risk for 6 common conditions. The results are both surprising and disappointing. Further studies should examine physicians' perception of the utility of prompts for family history risk.\n",
      "Question: Mammographic screening in Sami speaking municipalities and a control group. Are early outcome measures influenced by ethnicity? Context: Female citizens of Sami (the indigenous people of Norway) municipalities in northern Norway have a low risk of breast cancer. The objective of this study was to describe the attendance rate and outcome of the Norwegian Breast Cancer Screening Program (NBCSP) in the Sami-speaking municipalities and a control group. A retrospective registry-based study. The 8 municipalities included in the administration area of the Sami language law (Sami) were matched with a control group of 11 municipalities (non-Sami). Population data were accessed from Statistics Norway. Data regarding invitations and outcome in the NBCSP during the period 2001-2010 was derived from the Cancer Registry of Norway (CRN). The NBCSP targets women aged 50-69 years. Rates and percentages were compared using chi-square test with a p-value<0.05 as statistical significant. The attendance rate in the NBCSP was 78% in the Sami and 75% in the non-Sami population (p<0.01). The recall rates were 2.4 and 3.3% in the Sami and non-Sami population, respectively (p<0.01). The rate of invasive screen detected cancer was not significantly lower in the Sami group (p=0.14). The percentage of all breast cancers detected in the NBCSP among the Sami (67%) was lower compared with the non-Sami population (86%, p=0.06). Answer: Question: Mammographic screening in Sami speaking municipalities and a control group. Are early outcome measures influenced by ethnicity? Context: Female citizens of Sami (the indigenous people of Norway) municipalities in northern Norway have a low risk of breast cancer. The objective of this study was to describe the attendance rate and outcome of the Norwegian Breast Cancer Screening Program (NBCSP) in the Sami-speaking municipalities and a control group. A retrospective registry-based study. The 8 municipalities included in the administration area of the Sami language law (Sami) were matched with a control group of 11 municipalities (non-Sami). Population data were accessed from Statistics Norway. Data regarding invitations and outcome in the NBCSP during the period 2001-2010 was derived from the Cancer Registry of Norway (CRN). The NBCSP targets women aged 50-69 years. Rates and percentages were compared using chi-square test with a p-value<0.05 as statistical significant. The attendance rate in the NBCSP was 78% in the Sami and 75% in the non-Sami population (p<0.01). The recall rates were 2.4 and 3.3% in the Sami and non-Sami population, respectively (p<0.01). The rate of invasive screen detected cancer was not significantly lower in the Sami group (p=0.14). The percentage of all breast cancers detected in the NBCSP among the Sami (67%) was lower compared with the non-Sami population (86%, p=0.06). Answer: Despite a lower risk of breast cancer, the Sami attended the NBCSP more frequently than the control group. The recall and cancer detection rate was lower among the Sami compared with the non-Sami group.\n",
      "Question: Does increased patient awareness improve accrual into cancer-related clinical trials? Context: Oncology literature cites that only 2% to 4% of patients participate in research. Up to 85% of patients are unaware that clinical trials research is being conducted at their treatment facility or that they might be eligible to participate. It was hypothesized that patients' satisfaction with information regarding clinical trials would improve after targeted educational interventions, and accruals to clinical trials would increase in the year following those interventions. All new patients referred to the cancer center over a 4-month period were mailed a baseline survey to assess their knowledge of clinical research. Subsequently, educational interventions were provided, including an orientation session highlighting clinical trials, a pamphlet, and a reference to a clinical trials Web site. A postintervention survey was sent to the responders of the initial survey 3 months after the initial mailing. Patient satisfaction with information significantly increased after the interventions. There was no increase in subsequent enrollment in clinical trials. Patients who indicated an inclination to participate in clinical trials tended to have greater satisfaction with the information they received. Answer: Question: Does increased patient awareness improve accrual into cancer-related clinical trials? Context: Oncology literature cites that only 2% to 4% of patients participate in research. Up to 85% of patients are unaware that clinical trials research is being conducted at their treatment facility or that they might be eligible to participate. It was hypothesized that patients' satisfaction with information regarding clinical trials would improve after targeted educational interventions, and accruals to clinical trials would increase in the year following those interventions. All new patients referred to the cancer center over a 4-month period were mailed a baseline survey to assess their knowledge of clinical research. Subsequently, educational interventions were provided, including an orientation session highlighting clinical trials, a pamphlet, and a reference to a clinical trials Web site. A postintervention survey was sent to the responders of the initial survey 3 months after the initial mailing. Patient satisfaction with information significantly increased after the interventions. There was no increase in subsequent enrollment in clinical trials. Patients who indicated an inclination to participate in clinical trials tended to have greater satisfaction with the information they received. Answer: A set of educational interventions designed for cancer patients significantly improved their satisfaction with information on clinical research, but did not improve clinical trial enrollment of these participants as of 1 year after the study.\n",
      "Question: The inverse equity hypothesis: does it apply to coverage of cancer screening in middle-income countries? Context: It is uncertain whether the inverse equity hypothesis-the idea that new health interventions are initially primarily accessed by the rich, but that inequalities narrow with diffusion to the poor-holds true for cancer screening in low and middle income countries (LMICs).This study examines the relationship between overall coverage and economic inequalities in coverage of cancer screening in four middle-income countries. Secondary analyses of cross-sectional data from the WHO study on Global Ageing and Adult Health in China, Mexico, Russia and South Africa (2007-2010). Three regression-based methods were used to measure economic inequalities: (1) Adjusted OR; (2) Relative Index of Inequality (RII); and (3) Slope Index of Inequality. Coverage for breast cancer screening was 10.5% in South Africa, 19.3% in China, 33.8% in Russia and 43% in Mexico, and coverage for cervical cancer screening was 24% in South Africa, 27.2% in China, 63.7% in Mexico and 81.5% in Russia. Economic inequalities in screening participation were substantially lower or non-existent in countries with higher aggregate coverage, for both breast cancer screening (RII: 14.57 in South Africa, 4.90 in China, 2.01 in Mexico, 1.04 in Russia) and cervical cancer screening (RII: 3.60 in China, 2.47 in South Africa, 1.39 in Mexico, 1.12 in Russia). Answer: Question: The inverse equity hypothesis: does it apply to coverage of cancer screening in middle-income countries? Context: It is uncertain whether the inverse equity hypothesis-the idea that new health interventions are initially primarily accessed by the rich, but that inequalities narrow with diffusion to the poor-holds true for cancer screening in low and middle income countries (LMICs).This study examines the relationship between overall coverage and economic inequalities in coverage of cancer screening in four middle-income countries. Secondary analyses of cross-sectional data from the WHO study on Global Ageing and Adult Health in China, Mexico, Russia and South Africa (2007-2010). Three regression-based methods were used to measure economic inequalities: (1) Adjusted OR; (2) Relative Index of Inequality (RII); and (3) Slope Index of Inequality. Coverage for breast cancer screening was 10.5% in South Africa, 19.3% in China, 33.8% in Russia and 43% in Mexico, and coverage for cervical cancer screening was 24% in South Africa, 27.2% in China, 63.7% in Mexico and 81.5% in Russia. Economic inequalities in screening participation were substantially lower or non-existent in countries with higher aggregate coverage, for both breast cancer screening (RII: 14.57 in South Africa, 4.90 in China, 2.01 in Mexico, 1.04 in Russia) and cervical cancer screening (RII: 3.60 in China, 2.47 in South Africa, 1.39 in Mexico, 1.12 in Russia). Answer: Economic inequalities in breast and cervical cancer screening are low in LMICs with high screening coverage. These findings are consistent with the inverse equity hypothesis and indicate that high levels of equity in cancer screening are feasible even in countries with high income inequality.\n",
      "--------------------------------------------------\n",
      "Using general disease database (default).\n",
      "\n",
      "--- Passages for Symptom Query ---\n",
      "증상: Fever, Fatigue, Difficulty Breathing이(가) 있고, 나이: 40세, 성별: Male, 혈압: Normal, 콜레스테롤: High인 환자의 경우 Asthma일 수 있습니다. (나이: 40, 성별: Male, 혈압: Normal, 콜레스테롤: High)\n",
      "증상: Fever, Fatigue, Difficulty Breathing이(가) 있고, 나이: 40세, 성별: Male, 혈압: Normal, 콜레스테롤: High인 환자의 경우 Asthma일 수 있습니다. (나이: 40, 성별: Male, 혈압: Normal, 콜레스테롤: High)\n",
      "증상: Fever, Fatigue, Difficulty Breathing이(가) 있고, 나이: 32세, 성별: Female, 혈압: High, 콜레스테롤: Normal인 환자의 경우 Pneumonia일 수 있습니다. (나이: 32, 성별: Female, 혈압: High, 콜레스테롤: Normal)\n",
      "증상: Fever, Cough, Fatigue, Difficulty Breathing이(가) 있고, 나이: 50세, 성별: Female, 혈압: Normal, 콜레스테롤: High인 환자의 경우 Asthma일 수 있습니다. (나이: 50, 성별: Female, 혈압: Normal, 콜레스테롤: High)\n",
      "증상: Fever, Cough, Fatigue, Difficulty Breathing이(가) 있고, 나이: 60세, 성별: Female, 혈압: High, 콜레스테롤: High인 환자의 경우 Asthma일 수 있습니다. (나이: 60, 성별: Female, 혈압: High, 콜레스테롤: High)\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_passage(query, db, n_results=5):\n",
    "  results = db.query(query_texts=[query], n_results=n_results, include=['documents', 'metadatas'])\n",
    "  passages = []\n",
    "  for i in range(len(results['documents'][0])):\n",
    "      doc = results['documents'][0][i]\n",
    "      meta = results['metadatas'][0][i]\n",
    "      \n",
    "      passage_text = f\"{doc} (나이: {meta.get('age', '정보 없음')}, 성별: {meta.get('gender', '정보 없음')}, 혈압: {meta.get('blood_pressure', '정보 없음')}, 콜레스테롤: {meta.get('cholesterol', '정보 없음')})\"\n",
    "      passages.append(passage_text)\n",
    "  return passages\n",
    "# Perform embedding search\n",
    "passages = get_relevant_passage(\"Fever, Cough, Difficulty Breathing\", db, 5)\n",
    "\n",
    "\n",
    "def get_relevant_passage_intelligent(query, db_general, db_medical_qa, n_results=5):\n",
    "    \"\"\"\n",
    "    쿼리의 특성에 따라 적절한 ChromaDB 컬렉션에서 관련 구절을 가져옵니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 쿼리.\n",
    "        db_general (chromadb.api.models.Collection.Collection): 일반 질병 정보가 담긴 ChromaDB 컬렉션.\n",
    "        db_medical_qa (chromadb.api.models.Collection.Collection): PubMedQA long_answer가 담긴 ChromaDB 컬렉션.\n",
    "        n_results (int): 가져올 결과의 최대 개수.\n",
    "\n",
    "    Returns:\n",
    "        list: 관련 구절(문서 및 메타데이터 포함)의 리스트.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 쿼리 분석을 통해 어떤 DB를 사용할지 결정하는 로직 (예시)\n",
    "    # 실제 환경에서는 더 정교한 분류 모델이나 키워드 분석이 필요할 수 있습니다.\n",
    "    medical_keywords = [\"medication\", \"treatment\", \"diagnosis\", \"clinical\", \"study\", \"trial\", \"gene\", \"protein\", \"cell\", \"molecule\", \"pubmed\", \"article\", \"research\", \"efficacy\", \"mechanism\", \"pathway\", \"therapy\", \"syndrome\", \"disorder\"]\n",
    "    \n",
    "    # 쿼리에 의학 관련 키워드가 포함되어 있는지 확인\n",
    "    is_medical_query = any(keyword in query.lower() for keyword in medical_keywords)\n",
    "    \n",
    "    # 쿼리에 나이, 성별, 혈압, 콜레스테롤, 증상과 같은 개인 프로필 정보가 명시적으로 포함되어 있는지 확인\n",
    "    # 이는 'disease_rag_with_metadata.json' 데이터의 특성을 고려한 것입니다.\n",
    "    is_profile_specific_query = bool(re.search(r'(나이|성별|혈압|콜레스테롤|증상):', query))\n",
    "\n",
    "    selected_db = None\n",
    "    passages = []\n",
    "\n",
    "    if is_profile_specific_query:\n",
    "        # 개인 프로필 정보가 명시적으로 포함된 경우, 일반 질병 DB를 우선적으로 사용\n",
    "        print(\"Using general disease database (profile-specific query detected).\")\n",
    "        selected_db = db_general\n",
    "    elif is_medical_query:\n",
    "        # 의학 관련 키워드가 포함된 경우, PubMedQA DB를 사용\n",
    "        print(\"Using PubMedQA medical QA database (medical keywords detected).\")\n",
    "        selected_db = db_medical_qa\n",
    "    else:\n",
    "        # 둘 다 아닌 경우 (일반적인 증상 쿼리 등), 일반 질병 DB를 기본으로 사용\n",
    "        print(\"Using general disease database (default).\")\n",
    "        selected_db = db_general\n",
    "\n",
    "    if selected_db:\n",
    "        results = selected_db.query(query_texts=[query], n_results=n_results, include=['documents', 'metadatas'])\n",
    "        \n",
    "        for i in range(len(results['documents'][0])):\n",
    "            doc = results['documents'][0][i]\n",
    "            meta = results['metadatas'][0][i]\n",
    "            \n",
    "            # 선택된 DB에 따라 passage_text 형식을 조정\n",
    "            if selected_db == db_general:\n",
    "                passage_text = f\"{doc} (나이: {meta.get('age', '정보 없음')}, 성별: {meta.get('gender', '정보 없음')}, 혈압: {meta.get('blood_pressure', '정보 없음')}, 콜레스테롤: {meta.get('cholesterol', '정보 없음')})\"\n",
    "            elif selected_db == db_medical_qa:\n",
    "                # PubMedQA 데이터의 메타데이터 구조에 맞게 조정\n",
    "                passage_text = f\"Question: {meta.get('question', '정보 없음')} Context: {meta.get('context', '정보 없음')} Answer: {doc}\"\n",
    "            passages.append(passage_text)\n",
    "    else:\n",
    "        print(\"No suitable database found for the query.\")\n",
    "\n",
    "    return passages\n",
    "\n",
    "# 예시 사용:\n",
    "# 먼저, 위에서 정의한 db와 db_pubmedqa_long_answers가 생성되어 있어야 합니다.\n",
    "\n",
    "# 일반 질병 쿼리 예시\n",
    "query_general = \"나이: 30세, 성별: Female, 증상: 기침, 콧물, 인후통\"\n",
    "passages_general = get_relevant_passage_intelligent(query_general, db, db_pubmedqa_long_answers, 5)\n",
    "print(\"\\n--- Passages for General Query ---\")\n",
    "for p in passages_general:\n",
    "    print(p)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 의학 논문 쿼리 예시\n",
    "query_medical = \"Can tailored interventions increase mammography use among HMO women? A clinical study\"\n",
    "passages_medical = get_relevant_passage_intelligent(query_medical, db, db_pubmedqa_long_answers, 5)\n",
    "print(\"\\n--- Passages for Medical QA Query ---\")\n",
    "for p in passages_medical:\n",
    "    print(p)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 일반적인 증상 쿼리 (기본적으로 일반 질병 DB 사용)\n",
    "query_symptom = \"Fever, Fatigue, Difficulty Breathing\"\n",
    "passages_symptom = get_relevant_passage_intelligent(query_symptom, db, db_pubmedqa_long_answers, 5)\n",
    "print(\"\\n--- Passages for Symptom Query ---\")\n",
    "for p in passages_symptom:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using general disease database (profile-specific query detected).\n",
      "--- LLM 답변 ---\n",
      "안녕하세요! 심각한 공부하기 싫음이 있으시군요. 학업에 대한 의욕이 저하되어 힘든 시간을 보내고 계시는 것 같아 안타깝습니다.\n",
      "\n",
      "임상 데이터에 따르면 25세 남성분들에게서 비슷한 어려움을 겪는 사례가 종종 보고됩니다. 특히 정상 혈압과 콜레스테롤 수치를 유지하고 계신 분들에게서도 나타날 수 있는 현상입니다. 이러한 증상은 일시적인 무기력감이나 스트레스, 번아웃(Burnout)과 관련이 있을 수 있습니다.\n",
      "\n",
      "번아웃은 장기간에 걸쳐 과도한 스트레스에 시달린 결과, 신체적, 정신적으로 극도의 피로감을 느끼는 상태를 말합니다. 단순히 공부가 싫은 감정을 넘어, 무기력감, 집중력 저하, 의욕 상실 등의 증상을 동반할 수 있습니다.\n",
      "\n",
      "이럴 때는 다음과 같은 생활 습관 개선을 통해 어려움을 극복하는 데 도움을 줄 수 있습니다:\n",
      "\n",
      "- **충분한 휴식:** 학업에서 잠시 벗어나 좋아하는 활동을 하거나 편안하게 휴식을 취하며 에너지를 재충전하세요.\n",
      "- **균형 잡힌 식단:** 규칙적인 식사를 통해 몸에 필요한 영양소를 공급하고, 특히 뇌 기능에 도움이 되는 음식을 섭취하세요.\n",
      "- **가벼운 운동:** 산책이나 스트레칭과 같은 가벼운 운동은 스트레스 해소와 기분 전환에 도움이 됩니다.\n",
      "- **취미 활동:** 학업 외에 즐거움을 느낄 수 있는 취미 활동을 통해 스트레스를 해소하고 삶의 활력을 되찾으세요.\n",
      "- **수면 환경 개선:** 규칙적인 수면 습관을 유지하고, 잠들기 전 스마트폰 사용을 줄이는 등 수면의 질을 높이기 위해 노력하세요.\n",
      "- **긍정적인 마음 유지:** 자신을 격려하고 긍정적인 생각을 하도록 노력하며, 작은 성공에도 스스로를 칭찬해주세요.\n",
      "\n",
      "만약 무기력감이 지속되거나 다른 불편한 증상이 동반된다면, 단순한 번아웃이 아닐 수 있습니다. 드물게는 다른 심리적인 어려움이 원인일 수도 있습니다.\n",
      "\n",
      "더 궁금한 점이 있으시면 언제든지 다시 질문해주세요. 항상 건강하고 행복하시길 바랍니다!\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(query, relevant_passages):\n",
    "  escaped = \" \".join([p.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \") for p in relevant_passages])\n",
    "  prompt = f\"\"\"\n",
    "  당신은 사용자의 증상과 개인 프로필 정보를 기반으로 질병을 설명하고, **일상생활에서 할 수 있는 구체적이고 실용적인 조언을 상세하게 제공하는** 의료 상담 도우미입니다. 당신의 답변은 정보가 풍부하고 친절하며, **극단적이거나 심각한 질병을 직접적으로 진단하거나 추천하는 뉘앙스를 피해야 합니다.** 답변은 최소 100단어 이상으로 작성해 주세요.\n",
    "\n",
    "  **단계별 지시사항:**\n",
    "  1. 사용자 질문을 이해하고 핵심 증상(예: 기침, 콧물)을 정확하고 상세하게 파악하세요.\n",
    "  2. 제공된 '관련 정보 (PASSAGE)'를 면밀히 검토하여 사용자 증상과 가장 밀접하게 일치하는 질병(들)을 식별하되, **데이터에 기반한 질병 연관성을 언급하되 불필요하게 심각성을 강조하지 마세요.**\n",
    "  3. **여러 질병이 검색될 경우, 가장 일반적이거나 흔한 질환(예: 감기, 알레르기)을 우선적으로 상세히 설명하고, 그 다음으로 관련된 다른 질병들도 간략하게 제시하세요.**\n",
    "  4. 나이, 성별, 혈압, 콜레스테롤 수치와 같은 환자 프로필 정보가 있다면, 이를 **답변의 서론 부분에 해당 질병이 특정 프로필의 환자에게서 관찰될 수 있는 '사례'로 자연스럽게 통합하여 설명의 깊이를 더하세요.** 질병 진단의 직접적인 근거로 오해되지 않도록 주의하세요.\n",
    "  5. 답변은 정보가 풍부하고 명확하며 친절하게 작성하며, 다음 **상세 권장 출력 형식**을 따르되, **세부적인 구문은 모델의 자연스러운 생성에 맡기세요.**\n",
    "\n",
    "  **상세 권장 출력 형식:**\n",
    "  안녕하세요! [사용자 질문에서 파악된 증상]이(가) 있으시군요. 불편하시겠지만, 몇 가지 가능한 원인과 생활 속 대처법을 함께 알아보겠습니다.\n",
    "\n",
    "  (선택적: 임상 데이터에 따르면, [관련 정보의 나이]세 [관련 정보의 성별] 환자 중 [관련 정보의 혈압] 혈압과 [관련 정보의 콜레스테롤] 콜레스테롤 수치를 가진 분들에게서 [해당 질병과 연결된 증상]이 관찰된 사례가 있습니다.) 이러한 증상들은 [관련 정보에서 찾은 가장 일반적이고 가능성 높은 질병]과 관련이 있을 수 있습니다.\n",
    "\n",
    "  [질병에 대한 간략한 추가 설명 (2-3문장)]. 이 질병의 일반적인 경과나 특징에 대해 간략히 설명해 주세요.\n",
    "\n",
    "  이럴 때는 다음과 같은 생활 습관 개선을 통해 증상 완화에 도움을 줄 수 있습니다:\n",
    "  - **충분한 휴식:** 몸이 회복하는 데 필요한 시간을 주세요.\n",
    "  - **수분 섭취:** 따뜻한 물, 차 등을 자주 마셔 목을 촉촉하게 유지하고 탈수를 예방하세요.\n",
    "  - **실내 환경 관리:** 적절한 실내 습도를 유지하고 환기를 자주 해주세요.\n",
    "  - **영양가 있는 음식 섭취:** 면역력 강화를 위해 비타민과 미네랄이 풍부한 음식을 드세요.\n",
    "  - [추가적인 일반적인 조언 1 (예: 스트레스 관리, 가벼운 운동 등)]\n",
    "  - [추가적인 일반적인 조언 2 (예: 마스크 착용, 손 씻기 등)]\n",
    "\n",
    "  만약 [사용자 질문에서 파악된 증상] 외에 다른 불편한 증상이 있거나, 현재 증상이 나아지지 않고 오히려 심해진다면 [다른 관련 질병]일 수도 있습니다. (이때, 극단적인 질병은 가급적 언급하지 않거나, \"드물게는 ~일 수도 있습니다\"와 같이 조심스러운 표현을 사용하세요.)\n",
    "\n",
    "  더 궁금한 점이 있으시면 언제든지 다시 질문해주세요. 항상 건강하시길 바랍니다.\n",
    "\n",
    "  아래는 참고할 수 있는 임상 데이터입니다:\n",
    "  - 사용자 질문 (QUESTION): \\\"{query}\\\"\n",
    "  - 관련 정보 (PASSAGE): \\\"{escaped}\\\"\n",
    "\n",
    "  **주의사항:**\n",
    "  - 병원 방문 및 전문적인 상담을 직접적으로 권유하는 문구는 최종 답변에 포함하지 마세요.\n",
    "  - PASSAGE에 영어 단어가 포함되어 있다면, 괄호 안에 한글 뜻을 함께 제공해 주세요.\n",
    "  - **제공된 정보 내에서 '기침'과 '습진'의 연관성이 있더라도, '기침'이라는 증상에 더 일반적이고 흔한 질병(예: Common Cold, Influenza)이 있다면 이를 우선적으로 고려하여 답변하세요.**\n",
    "  - **'말라리아'와 같이 심각한 질병은 사용자가 직접적으로 언급하지 않는 한, 일반적인 증상만으로는 추천하지 마세요.**\n",
    "\n",
    "  ANSWER:\n",
    "  \"\"\".format(query=query, relevant_passages=escaped)\n",
    "  return prompt\n",
    "# 예시 사용\n",
    "query = \"나이: 25세, 성별: Male, 혈압: Normal, 콜레스테롤: Normal, 증상 : 심각한 공부하기 싫음\"\n",
    "passages = get_relevant_passage_intelligent(query_general, db, db_pubmedqa_long_answers, 5)\n",
    "prompt = make_prompt(query, passages)\n",
    "\n",
    "#print(prompt)\n",
    "\n",
    "MODEL_ID = \"gemini-2.0-flash\"\n",
    "answer = client.models.generate_content(\n",
    "    model = MODEL_ID,\n",
    "    contents = prompt\n",
    ")\n",
    "# 변경 시작: 'ANSWER:' 이후의 텍스트만 추출하고 앞뒤 공백 제거\n",
    "final_answer = answer.text.split(\"ANSWER:\")\n",
    "if len(final_answer) > 1:\n",
    "    final_answer = final_answer[1].strip()\n",
    "else:\n",
    "    final_answer = answer.text.strip()\n",
    "   \n",
    "# 6. 결과 출력\n",
    "print(\"--- LLM 답변 ---\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5df3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading PubMedQA dataset...\n",
      "dict_keys(['train'])\n",
      "PubMedQA test set loaded with 1000 examples.\n",
      "\n",
      "Evaluating on 50 PubMedQA samples for Accuracy...\n",
      "Quota exceeded. Retrying after 35 seconds... (Sample 16)\n",
      "Quota exceeded. Retrying after 35 seconds... (Sample 33)\n",
      "Quota exceeded. Retrying after 35 seconds... (Sample 49)\n",
      "\n",
      "--- PubMedQA 평가 결과 (정확도) ---\n",
      "평가 샘플 수: 47\n",
      "정확도: 0.2979\n",
      "\n",
      "--- PubMedQA 평가 예시 (정확도) ---\n",
      "질문: Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?\n",
      "정답 (Ground Truth Decision): yes\n",
      "LLM 응답: No\n",
      "정확도 일치 여부: False\n",
      "--------------------------------------------------\n",
      "질문: Landolt C and snellen e acuity: differences in strabismus amblyopia?\n",
      "정답 (Ground Truth Decision): no\n",
      "LLM 응답: No\n",
      "정확도 일치 여부: True\n",
      "--------------------------------------------------\n",
      "질문: Syncope during bathing in infants, a pediatric form of water-induced urticaria?\n",
      "정답 (Ground Truth Decision): yes\n",
      "LLM 응답: No\n",
      "정확도 일치 여부: False\n",
      "--------------------------------------------------\n",
      "질문: Are the long-term results of the transanal pull-through equal to those of the transabdominal pull-through?\n",
      "정답 (Ground Truth Decision): no\n",
      "LLM 응답: No\n",
      "정확도 일치 여부: True\n",
      "--------------------------------------------------\n",
      "질문: Can tailored interventions increase mammography use among HMO women?\n",
      "정답 (Ground Truth Decision): yes\n",
      "LLM 응답: No\n",
      "정확도 일치 여부: False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 기존 make_prompt_for_pubmedqa 함수는 긴 답변을 유도하므로, 짧은 답변을 위한 새로운 프롬프트 함수가 필요합니다.\n",
    "def make_short_answer_prompt_for_pubmedqa(query, relevant_passages):\n",
    "    escaped_passages = \" \".join([p.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\\\n\", \" \") for p in relevant_passages])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    당신은 의학적 질문에 대해 'Yes', 'No'로만 답변하는 의료 AI 도우미입니다.\n",
    "    제공된 '참고 정보'를 바탕으로 '의학적 질문'에 대한 답변을 생성하세요.\n",
    "\n",
    "    **다음 지침을 엄격히 따르세요:**\n",
    "    1.  **'Yes'로 답변하는 경우:** '참고 정보'에 '의학적 질문'에 대한 직접적이고 명확한 긍정적 증거가 있을 경우에만 'Yes'라고 답변하세요.\n",
    "    2.  **'No'로 답변하는 경우:** '참고 정보'에 '의학적 질문'에 대한 직접적이고 명확한 부정적 증거가 있거나, 질문의 내용이 '참고 정보'와 명백히 상반될 경우에만 'No'라고 답변하세요.\n",
    "   \n",
    "    다른 어떠한 설명도 추가하지 말고, 오직 하나의 단어('Yes', 'No')로만 답변해야 합니다.\n",
    "\n",
    "    **의학적 질문 (QUESTION):** \\\"{query}\\\"\n",
    "    **참고 정보 (PASSAGE):** \\\"{escaped_passages}\\\"\n",
    "\n",
    "    ANSWER:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 평가 함수 변경: ROUGE 대신 정확도 측정\n",
    "def evaluate_accuracy_pubmedqa(llm_response: str, ground_truth_decision: str) -> bool:\n",
    "    # 모델의 응답을 정규화 (대소문자 무시, 공백 제거 등)\n",
    "    normalized_llm_response = llm_response.strip().lower()\n",
    "    normalized_ground_truth = ground_truth_decision.strip().lower()\n",
    "\n",
    "    return normalized_llm_response == normalized_ground_truth\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 메인 평가 실행 부분 수정\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nLoading PubMedQA dataset...\")\n",
    "pubmedqa_dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\")\n",
    "print(pubmedqa_dataset.keys())\n",
    "pubmedqa_test_data = pubmedqa_dataset['train']\n",
    "\n",
    "print(f\"PubMedQA test set loaded with {len(pubmedqa_test_data)} examples.\")\n",
    "\n",
    "all_accuracies = []\n",
    "example_evaluations = []\n",
    "\n",
    "num_samples_to_evaluate = 50\n",
    "\n",
    "print(f\"\\nEvaluating on {num_samples_to_evaluate} PubMedQA samples for Accuracy...\")\n",
    "\n",
    "for i, entry in enumerate(pubmedqa_test_data):\n",
    "    if i >= num_samples_to_evaluate:\n",
    "        break\n",
    "\n",
    "    question = entry['question']\n",
    "    ground_truth_decision = entry['final_decision'] # 'long_answer' 대신 'final_decision' 사용\n",
    "\n",
    "    relevant_passages = get_relevant_passage(\"Fever, Cough, Difficulty Breathing\", db, 5)\n",
    "\n",
    "    # 새로운 짧은 답변 프롬프트 사용\n",
    "    prompt = make_short_answer_prompt_for_pubmedqa(question, relevant_passages)\n",
    "\n",
    "    try:\n",
    "        MODEL_ID = \"gemini-2.0-flash\"\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_ID,\n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "        llm_response = response.text.split(\"ANSWER:\")\n",
    "        if len(llm_response) > 1:\n",
    "            llm_response = llm_response[1].strip()\n",
    "        else:\n",
    "            llm_response = response.text.strip()\n",
    "\n",
    "        # 정확도 평가\n",
    "        is_correct = evaluate_accuracy_pubmedqa(llm_response, ground_truth_decision)\n",
    "        all_accuracies.append(is_correct)\n",
    "\n",
    "        if i < 5:\n",
    "            example_evaluations.append({\n",
    "                'question': question,\n",
    "                'ground_truth_decision': ground_truth_decision,\n",
    "                'llm_response': llm_response,\n",
    "                'is_correct': is_correct\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"429 RESOURCE_EXHAUSTED\" in str(e):\n",
    "            retry_after_seconds = 35\n",
    "            print(f\"Quota exceeded. Retrying after {retry_after_seconds} seconds... (Sample {i})\")\n",
    "            time.sleep(retry_after_seconds)\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Error processing sample {i}: {e}\")\n",
    "            all_accuracies.append(False) # 오류 발생 시 오답으로 처리\n",
    "\n",
    "# 평균 정확도 계산\n",
    "if all_accuracies:\n",
    "    total_correct = sum(all_accuracies)\n",
    "    accuracy = total_correct / len(all_accuracies)\n",
    "    print(\"\\n--- PubMedQA 평가 결과 (정확도) ---\")\n",
    "    print(f\"평가 샘플 수: {len(all_accuracies)}\")\n",
    "    print(f\"정확도: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo evaluation results to display.\")\n",
    "\n",
    "# 예시 평가 결과 출력\n",
    "print(\"\\n--- PubMedQA 평가 예시 (정확도) ---\")\n",
    "for ex in example_evaluations:\n",
    "    print(f\"질문: {ex['question']}\")\n",
    "    print(f\"정답 (Ground Truth Decision): {ex['ground_truth_decision']}\")\n",
    "    print(f\"LLM 응답: {ex['llm_response']}\")\n",
    "    print(f\"정확도 일치 여부: {ex['is_correct']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading PubMedQA dataset...\n",
      "dict_keys(['train'])\n",
      "PubMedQA test set loaded with 1000 examples.\n",
      "\n",
      "Evaluating on 50 PubMedQA samples for Accuracy...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_relevant_passage_intelligent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m question = entry[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     54\u001b[39m ground_truth_decision = entry[\u001b[33m'\u001b[39m\u001b[33mfinal_decision\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;66;03m# 'long_answer' 대신 'final_decision' 사용\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m relevant_passages = \u001b[43mget_relevant_passage_intelligent\u001b[49m(query_general, db, db_pubmedqa_long_answers, \u001b[32m5\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# 새로운 짧은 답변 프롬프트 사용\u001b[39;00m\n\u001b[32m     59\u001b[39m prompt = make_short_answer_prompt_for_pubmedqa(question, relevant_passages)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_relevant_passage_intelligent' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 기존 make_prompt_for_pubmedqa 함수는 긴 답변을 유도하므로, 짧은 답변을 위한 새로운 프롬프트 함수가 필요합니다.\n",
    "def make_short_answer_prompt_for_pubmedqa(query, relevant_passages):\n",
    "    escaped_passages = \" \".join([p.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\\\n\", \" \") for p in relevant_passages])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    당신은 의학적 질문에 대해 'Yes', 'No', 'Maybe'로만 답변하는 의료 AI 도우미입니다.\n",
    "    제공된 '참고 정보'를 바탕으로 '의학적 질문'에 대한 답변을 생성하세요.\n",
    "\n",
    "    **다음 지침을 엄격히 따르세요:**\n",
    "    1.  **'Yes'로 답변하는 경우:** '참고 정보'에 '의학적 질문'에 대한 직접적이고 명확한 긍정적 증거가 있을 경우에 'Yes'라고 답변하세요.\n",
    "    2.  **'No'로 답변하는 경우:** '참고 정보'에 '의학적 질문'에 대한 직접적이고 명확한 부정적 증거가 있거나, 질문의 내용이 '참고 정보'와 명백히 상반될 경우에 'No'라고 답변하세요.\n",
    "    3.  **'No'로 답변하는 경우:** 둘중 아니면 Maybe로 답하시오\n",
    "    다른 어떠한 설명도 추가하지 말고, 오직 하나의 단어('Yes', 'No', 'Maybe')로만 답변해야 합니다.\n",
    "\n",
    "    **의학적 질문 (QUESTION):** \\\"{query}\\\"\n",
    "    **참고 정보 (PASSAGE):** \\\"{escaped_passages}\\\"\n",
    "\n",
    "    ANSWER:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 평가 함수 변경: ROUGE 대신 정확도 측정\n",
    "def evaluate_accuracy_pubmedqa(llm_response: str, ground_truth_decision: str) -> bool:\n",
    "    # 모델의 응답을 정규화 (대소문자 무시, 공백 제거 등)\n",
    "    normalized_llm_response = llm_response.strip().lower()\n",
    "    normalized_ground_truth = ground_truth_decision.strip().lower()\n",
    "\n",
    "    return normalized_llm_response == normalized_ground_truth\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 메인 평가 실행 부분 수정\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nLoading PubMedQA dataset...\")\n",
    "pubmedqa_dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\")\n",
    "print(pubmedqa_dataset.keys())\n",
    "pubmedqa_test_data = pubmedqa_dataset['train']\n",
    "\n",
    "print(f\"PubMedQA test set loaded with {len(pubmedqa_test_data)} examples.\")\n",
    "\n",
    "all_accuracies = []\n",
    "example_evaluations = []\n",
    "\n",
    "num_samples_to_evaluate = 50\n",
    "\n",
    "print(f\"\\nEvaluating on {num_samples_to_evaluate} PubMedQA samples for Accuracy...\")\n",
    "\n",
    "for i, entry in enumerate(pubmedqa_test_data):\n",
    "    if i >= num_samples_to_evaluate:\n",
    "        break\n",
    "\n",
    "    question = entry['question']\n",
    "    ground_truth_decision = entry['final_decision'] # 'long_answer' 대신 'final_decision' 사용\n",
    "\n",
    "    relevant_passages = get_relevant_passage_intelligent(query_general, db, db_pubmedqa_long_answers, 5)\n",
    "\n",
    "    # 새로운 짧은 답변 프롬프트 사용\n",
    "    prompt = make_short_answer_prompt_for_pubmedqa(question, relevant_passages)\n",
    "\n",
    "    try:\n",
    "        MODEL_ID = \"gemini-2.0-flash\"\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_ID,\n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "        llm_response = response.text.split(\"ANSWER:\")\n",
    "        if len(llm_response) > 1:\n",
    "            llm_response = llm_response[1].strip()\n",
    "        else:\n",
    "            llm_response = response.text.strip()\n",
    "\n",
    "        # 정확도 평가\n",
    "        is_correct = evaluate_accuracy_pubmedqa(llm_response, ground_truth_decision)\n",
    "        all_accuracies.append(is_correct)\n",
    "\n",
    "        if i < 5:\n",
    "            example_evaluations.append({\n",
    "                'question': question,\n",
    "                'ground_truth_decision': ground_truth_decision,\n",
    "                'llm_response': llm_response,\n",
    "                'is_correct': is_correct\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"429 RESOURCE_EXHAUSTED\" in str(e):\n",
    "            retry_after_seconds = 35\n",
    "            print(f\"Quota exceeded. Retrying after {retry_after_seconds} seconds... (Sample {i})\")\n",
    "            time.sleep(retry_after_seconds)\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Error processing sample {i}: {e}\")\n",
    "            all_accuracies.append(False) # 오류 발생 시 오답으로 처리\n",
    "\n",
    "# 평균 정확도 계산\n",
    "if all_accuracies:\n",
    "    total_correct = sum(all_accuracies)\n",
    "    accuracy = total_correct / len(all_accuracies)\n",
    "    print(\"\\n--- PubMedQA 평가 결과 (정확도) ---\")\n",
    "    print(f\"평가 샘플 수: {len(all_accuracies)}\")\n",
    "    print(f\"정확도: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo evaluation results to display.\")\n",
    "\n",
    "# 예시 평가 결과 출력\n",
    "print(\"\\n--- PubMedQA 평가 예시 (정확도) ---\")\n",
    "for ex in example_evaluations:\n",
    "    print(f\"질문: {ex['question']}\")\n",
    "    print(f\"정답 (Ground Truth Decision): {ex['ground_truth_decision']}\")\n",
    "    print(f\"LLM 응답: {ex['llm_response']}\")\n",
    "    print(f\"정확도 일치 여부: {ex['is_correct']}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
