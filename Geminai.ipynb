{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301eefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key='AIzaSyCHcy8oO-XhjsLCTdzLB64t9XR01OanbpM')\n",
    "\n",
    "\n",
    "for m in client.models.list():\n",
    "  if 'embedContent' in m.supported_actions:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9f7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "  def __call__(self, input: Documents) -> Embeddings:\n",
    "    EMBEDDING_MODEL_ID = \"models/embedding-001\"\n",
    "    title = \"Custom query\"\n",
    "    response = client.models.embed_content(\n",
    "        model=EMBEDDING_MODEL_ID,\n",
    "        contents=input,\n",
    "        config=types.EmbedContentConfig(\n",
    "          task_type=\"retrieval_document\",\n",
    "          title=title\n",
    "        )\n",
    "    )\n",
    "    # 모든 문서의 임베딩 벡터를 리스트로 반환\n",
    "    return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322eb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eh589\\AppData\\Local\\Temp\\ipykernel_9752\\2476913475.py:27: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function=GeminiEmbeddingFunction()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#chroma_client.delete_collection(\"my_collection\")\n",
    "def preprocess_metadata(metadata):\n",
    "    new_metadata = {}\n",
    "    for k, v in metadata.items():\n",
    "        if isinstance(v, list):\n",
    "            new_metadata[k] = \", \".join(map(str, v))  # 리스트를 문자열로 변환\n",
    "        else:\n",
    "            new_metadata[k] = v\n",
    "    return new_metadata\n",
    "def batch_add(collection, documents, metadatas, ids, batch_size=100):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch_docs = documents[i:i+batch_size]\n",
    "        batch_metas = metadatas[i:i+batch_size]\n",
    "        batch_ids = ids[i:i+batch_size]\n",
    "        collection.add(\n",
    "            documents=batch_docs,\n",
    "            metadatas=batch_metas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "def create_chroma_db(json_data, name):\n",
    "    import chromadb\n",
    "\n",
    "    chroma_client = chromadb.Client()\n",
    "    db = chroma_client.create_collection(\n",
    "        name=name,\n",
    "        embedding_function=GeminiEmbeddingFunction()\n",
    "    )\n",
    "\n",
    "    # JSON 데이터에서 텍스트, 메타데이터, id 추출\n",
    "    documents = [item[\"text\"] for item in json_data]\n",
    "    metadatas = [preprocess_metadata(item[\"metadata\"]) for item in json_data]\n",
    "    ids = [str(i) for i in range(len(json_data))]\n",
    "    \n",
    "    batch_add(db, documents, metadatas, ids, batch_size=100)\n",
    "   \n",
    "    return db\n",
    "with open('disease_rag_with_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "db = create_chroma_db(data, \"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cb907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  IDs                                          Documents  \\\n",
      "0   0  Fever, Fatigue, Difficulty Breathing 증상이 있는 경우...   \n",
      "1   1      Cough, Fatigue 증상이 있는 경우 Common Cold일 수 있습니다.   \n",
      "2   2           Cough, Fatigue 증상이 있는 경우 Eczema일 수 있습니다.   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [ 3.16955782e-02 -4.14985903e-02 -4.31520194e-...  \n",
      "1  [ 7.59642050e-02 -6.42082170e-02 -7.00410604e-...  \n",
      "2  [ 6.10879771e-02 -5.23152687e-02 -7.92896152e-...  \n"
     ]
    }
   ],
   "source": [
    "sample_data = db.get(include=['documents', 'embeddings'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"IDs\": sample_data['ids'][:3],\n",
    "    \"Documents\": sample_data['documents'][:3],\n",
    "    \"Embeddings\": [str(emb)[:50] + \"...\" for emb in sample_data['embeddings'][:3]]  # Truncate embeddings\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4861eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fever, Fatigue, Difficulty Breathing 증상이 있는 경우 Asthma일 수 있습니다.', 'Fever, Fatigue, Difficulty Breathing 증상이 있는 경우 Asthma일 수 있습니다.', 'Fever, Fatigue 증상이 있는 경우 Asthma일 수 있습니다.', 'Fever, Cough, Fatigue, Difficulty Breathing 증상이 있는 경우 Asthma일 수 있습니다.', 'Fever, Cough, Fatigue, Difficulty Breathing 증상이 있는 경우 Asthma일 수 있습니다.']\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_passage(query, db, n_results=5):\n",
    "  passages = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
    "  return passages\n",
    "# Perform embedding search\n",
    "passages = get_relevant_passage(\"Fever, Cough, Difficulty Breathing\", db, 5)\n",
    "print(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  당신은 사용자의 증상에 대해 의학적으로 도움을 주는 상담 도우미입니다.\n",
      "\n",
      "  아래는 참고할 수 있는 임상 데이터입니다:\n",
      "  - 사용자 질문 (QUESTION): \"나는 기침을 자주하고 요즘 콧물도 나는 것 같아\"\n",
      "  - 관련 정보 (PASSAGE): \"Fatigue 증상이 있는 경우 Depression일 수 있습니다. Fatigue 증상이 있는 경우 Depression일 수 있습니다. Cough 증상이 있는 경우 Eczema일 수 있습니다. Cough 증상이 있는 경우 Eczema일 수 있습니다. Fatigue 증상이 있는 경우 Dementia일 수 있습니다.\"\n",
      "\n",
      "이 정보를 참고하여 사용자에게 친절하고 정확하게 답변해 주세요.\n",
      "또한 병원 방문 및 전문적인 상담을 권유하지 마세요.\n",
      "또한 PASSAGE에 영어 단어가 포함되어 있다면, 괄호 안에 한글 뜻을 함께 제공해 주세요.\n",
      "\n",
      "답변은 아래 ANSWER: 이후에 이어서 작성해 주세요.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "['안녕하세요. 기침과 콧물 증상으로 걱정이 많으시군요. 알려주신 정보에 따르면 기침(Cough) 증상은 습진(Eczema)과 관련이 있을 수 있습니다. 콧물에 대한 직접적인 정보는 없지만, 기침과 함께 나타나는 증상인 만큼 몸 상태를 주의 깊게 살펴보시는 것이 좋겠습니다. 충분한 휴식을 취하시고, 따뜻한 물을 자주 마시는 등 건강 관리에 신경 써 주세요.\\n']\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(query, relevant_passages):\n",
    "  escaped = \" \".join([p.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \") for p in relevant_passages])\n",
    "  prompt = f\"\"\"\n",
    "  당신은 사용자의 증상에 대해 의학적으로 도움을 주는 상담 도우미입니다.\n",
    "\n",
    "  아래는 참고할 수 있는 임상 데이터입니다:\n",
    "  - 사용자 질문 (QUESTION): \"{query}\"\n",
    "  - 관련 정보 (PASSAGE): \"{escaped}\"\n",
    "\n",
    "이 정보를 참고하여 사용자에게 친절하고 정확하게 답변해 주세요.\n",
    "또한 병원 방문 및 전문적인 상담을 권유하지 마세요.\n",
    "또한 PASSAGE에 영어 단어가 포함되어 있다면, 괄호 안에 한글 뜻을 함께 제공해 주세요.\n",
    "\n",
    "답변은 아래 ANSWER: 이후에 이어서 작성해 주세요.\n",
    "\n",
    "ANSWER:\n",
    "\"\"\".format(query=query, relevant_passages=escaped)\n",
    "  return prompt\n",
    "query = \"나는 기침을 자주하고 요즘 콧물도 나는 것 같아\"\n",
    "passages = get_relevant_passage(query, db, 5)\n",
    "prompt = make_prompt(query, passages)\n",
    "print(prompt)\n",
    "MODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-05-06\"] {\"allow-input\": true, \"isTemplate\": true}\n",
    "answer = client.models.generate_content(\n",
    "    model = MODEL_ID,\n",
    "    contents = prompt\n",
    ")\n",
    "print(answer.text.split(\"ANSWER:\"[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
